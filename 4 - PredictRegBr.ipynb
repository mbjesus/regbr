{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27189c5c",
   "metadata": {},
   "source": [
    "## ARTIFICIAL INTELLIGENCE ON LEGAL LANGUAGE PROCESSING: USING DEEP LEARNING TO FOUND THE REGULATORY LAW FRAMEWORK FOR THE THIRD SECTOR\n",
    "\n",
    "### Mauricio Barros de Jesus - mauriciobajesus@gmail.com \n",
    "### McCormick & Ryan (2019) inspired the source code.  Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning Tutorial with PyTorch. Retrieved from - https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f866cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f5cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.utils import resample, shuffle\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, matthews_corrcoef, auc, roc_curve\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score, recall_score \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43976a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfca2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18da2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(os.path.abspath('')).resolve()\n",
    "batch_size = 32\n",
    "max_length_bert = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e095b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regbr= pd.read_parquet(Path(os.path.join(BASE_DIR, 'dataset','regbr','dados_regbr_sentencas_v3.parquet')),engine='fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deeea2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1330190 entries, 0 to 1330189\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   id_sentenca          1330190 non-null  object\n",
      " 1   id_doc_base          1330190 non-null  int64 \n",
      " 2   tokens_total         1330190 non-null  int64 \n",
      " 3   tokens_no_stopwords  1330190 non-null  int64 \n",
      " 4   text_sentenca        1330190 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 50.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_regbr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24ebe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regbr[\"cat\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fa95ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'neuralmind/bert-base-portuguese-cased', #\"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(BASE_DIR,'models',f'model_state.save_3'))[\"model_state_dict\"])\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cae791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSentence(sentences,labels):\n",
    "    # Report the number of sentences.\n",
    "    #print('Number of test sentences: {:,}\\n'.format(len(sentences)))\n",
    "\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 512,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Create the DataLoader.\n",
    "    prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "    prediction_sampler = SequentialSampler(prediction_data)\n",
    "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "    \n",
    "    #print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions , true_labels, pred_vals = [], [], []\n",
    "\n",
    "    # Predict \n",
    "    for batch in prediction_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and \n",
    "        # speeding up prediction\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        pred_vals.append(pred_flat)\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    #print('DONE.')\n",
    "    #return predictions\n",
    "    return {\"pred_vals\":pred_vals,\"predictions\":predictions,\"true_labels\":true_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fea9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "sentences = df_regbr[\"text_sentenca\"].to_list()\n",
    "labels = df_regbr[\"cat\"].to_list()\n",
    "resp = predictSentence(sentences,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a888fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regbr[\"cat\"] = np.concatenate(resp[\"pred_vals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2706d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "setencesFP = [\n",
    "    '41652004_SENT_752750'\n",
    ",'3411966_SENT_8433868'\n",
    ",'5351979_SENT_6295772'\n",
    ",'42132004_SENT_3986864'\n",
    ",'42871990_SENT_3600713'\n",
    ",'47272016_SENT_1952602'\n",
    ",'48022017_SENT_8729859'\n",
    ",'69191993_SENT_3719152'\n",
    ",'281581991_SENT_3444194'\n",
    ",'289091994_SENT_1502504'\n",
    ",'297901999_SENT_5875010'\n",
    ",'610411994_SENT_5111085'\n",
    ",'626631998_SENT_6829088'\n",
    ",'627081998_SENT_7480837'\n",
    ",'653522005_SENT_6431382'\n",
    ",'655132005_SENT_4616080'\n",
    ",'656222005_SENT_2523068'\n",
    ",'682422014_SENT_5573007'\n",
    ",'685792015_SENT_1673217'\n",
    ",'689752017_SENT_8788943'\n",
    ",'691492017_SENT_654702'\n",
    ",'692212017_SENT_5100941'\n",
    ",'2139032019_SENT_7673157'\n",
    ",'2141132020_SENT_4313056'\n",
    ",'6102532020_SENT_8307676'\n",
    ",'6102532020_SENT_1258393'\n",
    ",'42186162001_SENT_9965428']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4984326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regbr.loc[df_regbr[\"id_sentenca\"].isin(setencesFP), \"cat\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9921ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1330190 entries, 0 to 1330189\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   id_sentenca          1330190 non-null  object\n",
      " 1   id_doc_base          1330190 non-null  int64 \n",
      " 2   tokens_total         1330190 non-null  int64 \n",
      " 3   tokens_no_stopwords  1330190 non-null  int64 \n",
      " 4   text_sentenca        1330190 non-null  object\n",
      " 5   cat                  1330190 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 60.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_regbr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47724e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regbr.to_parquet(Path(os.path.join(BASE_DIR,'dataset','results','dados_regbr_sentencas_predicted_25092022_v4.parquet')),engine=\"fastparquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e637e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1327679\n",
       "1       2511\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regbr[\"cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03451255",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfThirdSector = df_regbr[df_regbr[\"cat\"] == 1].copy()\n",
    "dfNotThirdSector = df_regbr[df_regbr[\"cat\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c02e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 710 entries, 15318 to 1328866\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   id_doc_base  710 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 11.1 KB\n"
     ]
    }
   ],
   "source": [
    "dfThirdSector[[\"id_doc_base\"]].drop_duplicates().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cddf9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfThirdSector.to_parquet(Path(os.path.join(BASE_DIR,'dataset','results','dados_regbr_sentencas_predicted_25092022_third_sec_v4.parquet')),engine=\"fastparquet\")\n",
    "dfThirdSector.to_excel(Path(os.path.join(BASE_DIR,'dataset','results','dados_regbr_sentencas_predicted_25092022_third_sec_v4.xlsx')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2b925fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 710 entries, 0 to 709\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   id_doc_base     710 non-null    int64\n",
      " 1   qtd_terc_setor  710 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 11.2 KB\n"
     ]
    }
   ],
   "source": [
    "dfThirdSectorQtdOcorrencias = pd.DataFrame(dfThirdSector[\"id_doc_base\"].value_counts()).reset_index()\n",
    "dfThirdSectorQtdOcorrencias.rename(columns={\"index\":\"id_doc_base2\",\"id_doc_base\":'qtd_terc_setor'},inplace=True)\n",
    "dfThirdSectorQtdOcorrencias.rename(columns={\"id_doc_base2\":\"id_doc_base\",\"qtd_terc_setor\":'qtd_terc_setor'},inplace=True)\n",
    "dfThirdSectorQtdOcorrencias.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46d78796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50994 entries, 0 to 50993\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   id_doc_base         50994 non-null  int64\n",
      " 1   qtd_not_terc_setor  50994 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 796.9 KB\n"
     ]
    }
   ],
   "source": [
    "dfNotThirdSectorQtdOcorrencias = pd.DataFrame(dfNotThirdSector[\"id_doc_base\"].value_counts()).reset_index()\n",
    "dfNotThirdSectorQtdOcorrencias.rename(columns={\"index\":\"id_doc_base2\",\"id_doc_base\":'qtd_not_terc_setor'},inplace=True)\n",
    "dfNotThirdSectorQtdOcorrencias.rename(columns={\"id_doc_base2\":\"id_doc_base\",\"qtd_not_terc_setor\":'qtd_not_terc_setor'},inplace=True)\n",
    "dfNotThirdSectorQtdOcorrencias.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12ae1ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_doc_base</th>\n",
       "      <th>qtd_terc_setor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2130192014</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>687262016</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_doc_base  qtd_terc_setor\n",
       "0   2130192014             259\n",
       "1    687262016             157"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfThirdSectorQtdOcorrencias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06211641",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias = dfNotThirdSectorQtdOcorrencias.merge(dfThirdSectorQtdOcorrencias, on=\"id_doc_base\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3282a267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50995 entries, 0 to 50994\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id_doc_base         50995 non-null  int64  \n",
      " 1   qtd_not_terc_setor  50994 non-null  float64\n",
      " 2   qtd_terc_setor      710 non-null    float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "dfResumoOcorrencias.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "892b784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfad7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias[\"metrica\"] = dfResumoOcorrencias.apply(lambda row: row[\"qtd_terc_setor\"]/(row[\"qtd_terc_setor\"] + row[\"qtd_not_terc_setor\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0936fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias.sort_values(by=\"metrica\",ascending=False,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7606f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFaixa(metrica):\n",
    "    faixa = 'Non Third Sector'\n",
    "    if metrica >= 0.6:\n",
    "        faixa = 'Focus on Third Sector'\n",
    "    elif  metrica >= 0.3:\n",
    "        faixa = 'Addresses Third Sector'\n",
    "    elif  metrica > 0:\n",
    "        faixa = 'Mentions to Third Sector'\n",
    "        \n",
    "    return faixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2c804f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias[\"faixa\"] = dfResumoOcorrencias[\"metrica\"].apply(calcFaixa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "100cee02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>faixa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non Third Sector</td>\n",
       "      <td>50285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mentions to Third Sector</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addresses Third Sector</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Focus on Third Sector</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  faixa\n",
       "0          Non Third Sector  50285\n",
       "1  Mentions to Third Sector    678\n",
       "2    Addresses Third Sector     29\n",
       "3     Focus on Third Sector      3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfResumoOcorrencias[\"faixa\"].value_counts()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89f0da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_doc_base</th>\n",
       "      <th>qtd_not_terc_setor</th>\n",
       "      <th>qtd_terc_setor</th>\n",
       "      <th>metrica</th>\n",
       "      <th>faixa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50994</th>\n",
       "      <td>6109152022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Focus on Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23432</th>\n",
       "      <td>675922011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>Focus on Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42569</th>\n",
       "      <td>663082007</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>Focus on Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47913</th>\n",
       "      <td>2142152022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>Addresses Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46334</th>\n",
       "      <td>294291996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>Addresses Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>4164871998</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Addresses Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>282461991</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>Addresses Third Sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>691902017</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>Addresses Third Sector</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_doc_base  qtd_not_terc_setor  qtd_terc_setor   metrica  \\\n",
       "50994   6109152022                 0.0             1.0  1.000000   \n",
       "23432    675922011                 8.0            15.0  0.652174   \n",
       "42569    663082007                 5.0             9.0  0.642857   \n",
       "47913   2142152022                 3.0             4.0  0.571429   \n",
       "46334    294291996                 4.0             5.0  0.555556   \n",
       "8710    4164871998                27.0            33.0  0.550000   \n",
       "12299    282461991                17.0            20.0  0.540541   \n",
       "5358     691902017                49.0            53.0  0.519608   \n",
       "\n",
       "                        faixa  \n",
       "50994   Focus on Third Sector  \n",
       "23432   Focus on Third Sector  \n",
       "42569   Focus on Third Sector  \n",
       "47913  Addresses Third Sector  \n",
       "46334  Addresses Third Sector  \n",
       "8710   Addresses Third Sector  \n",
       "12299  Addresses Third Sector  \n",
       "5358   Addresses Third Sector  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResumoOcorrencias[dfResumoOcorrencias[\"metrica\"]>=0.5].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "375b7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResumoOcorrencias.to_excel(Path(os.path.join(BASE_DIR,'dataset','results','dados_regbr_sentencas_resumo_ocorrencias_25092022_v4.xlsx')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d33944e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfResumoOcorrencias[dfResumoOcorrencias[\"metrica\"]>0].to_excel(Path(os.path.join(BASE_DIR,'dataset','results','dados_regbr_sentencas_resumo_ocorrencias_third_sector_25092022_v4.xlsx')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc0fee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 710 entries, 50994 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id_doc_base         710 non-null    int64  \n",
      " 1   qtd_not_terc_setor  710 non-null    float64\n",
      " 2   qtd_terc_setor      710 non-null    float64\n",
      " 3   metrica             710 non-null    float64\n",
      " 4   faixa               710 non-null    object \n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dfResumoOcorrencias[dfResumoOcorrencias[\"metrica\"]>0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7396ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1330190 entries, 0 to 1330189\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   id_sentenca          1330190 non-null  object\n",
      " 1   id_doc_base          1330190 non-null  int64 \n",
      " 2   tokens_total         1330190 non-null  int64 \n",
      " 3   tokens_no_stopwords  1330190 non-null  int64 \n",
      " 4   text_sentenca        1330190 non-null  object\n",
      " 5   cat                  1330190 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 60.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_regbr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce7b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
